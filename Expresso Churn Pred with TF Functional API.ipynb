{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expresso TF.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymSJkZ7bazdi",
        "outputId": "e6a6a975-b6fa-41f9-fa26-1a848e6c1b89"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJIjdrtea3GB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9f1f0009-ff45-4bb4-9436-43e2309692f2"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.set_printoptions(precision=4)\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHQLA5jkQaqE"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkyhK9Y2cumm"
      },
      "source": [
        "# Use to create Train/Evaluation/Test sets\n",
        "\n",
        "#pd_train_data = pd.read_csv('/content/drive/MyDrive/Expresso Churn/Train.csv')\n",
        "#pd_train_data.columns\n",
        "\n",
        "#-----Create a training and evaluation dataset-----\n",
        "\n",
        "#eval_length = int(len(pd_train_data)*0.8)\n",
        "#train_data = pd_train_data[:eval_length ]\n",
        "#eval_data = pd_train_data[eval_length: ]\n",
        "\n",
        "#train_data.to_csv(\"/content/drive/MyDrive/Expresso Churn/tfTrain.csv\", index=False)\n",
        "#eval_data.to_csv(\"/content/drive/MyDrive/Expresso Churn/tfEval.csv\", index=False)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_U5K-h9BdyOg",
        "outputId": "1d124617-aed0-4773-a6b1-d4abfe07b41a"
      },
      "source": [
        "tf_train_data = pd.read_csv(\"/content/drive/MyDrive/Expresso Churn/tfTrain.csv\")\n",
        "tf_train_data.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'REGION', 'TENURE', 'MONTANT', 'FREQUENCE_RECH', 'REVENUE',\n",
              "       'ARPU_SEGMENT', 'FREQUENCE', 'DATA_VOLUME', 'ON_NET', 'ORANGE', 'TIGO',\n",
              "       'ZONE1', 'ZONE2', 'MRG', 'REGULARITY', 'TOP_PACK', 'FREQ_TOP_PACK',\n",
              "       'CHURN'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4879LX26fYZ6"
      },
      "source": [
        "# Get unique tenures and regions to use later on for categorical encoding\n",
        "unique_tenures = tf_train_data['TENURE'].unique().tolist()\n",
        "unique_regions = tf_train_data['REGION'].unique().tolist()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USiOmvVmQatM"
      },
      "source": [
        "CSV_COLUMNS = tf_train_data.columns\n",
        "LABEL_COLUMN = 'CHURN'\n",
        "DEFAULTS = [['new_user'],['not_given'],['not_given'],\n",
        "            [0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],[0.0],\n",
        "            ['not_given'],[0.0],['not_given'],[0.0],[0]]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyglI_guYPJ7"
      },
      "source": [
        "def feature_engg_features(features):\n",
        "  # Add feature Engineering here\n",
        "\n",
        "  return(features)\n",
        "  \n",
        "\n",
        "def feature_engg(features, label):\n",
        "  #Add new features\n",
        "  features = feature_engg_features(features)\n",
        "\n",
        "  return(features, label) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uc78w4HYPOQ"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jziJdBxgQayP"
      },
      "source": [
        "def create_input_fn(filename, mode, vnum_epochs = None, batch_size = 512):\n",
        "  # filename can be a link/url to the file\n",
        "  def _input_fn(v_test=False):\n",
        "    file_list = tf.io.gfile.glob(filename)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "      # If in training mode\n",
        "      num_epochs = vnum_epochs \n",
        "    else:\n",
        "      num_epochs = 1 # end-of-input after this\n",
        "\n",
        "    #Create the dataset\n",
        "    dataset = tf.data.experimental.make_csv_dataset(filename,                           \n",
        "                                                    column_names=CSV_COLUMNS,\n",
        "                                                    column_defaults=DEFAULTS,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    label_name=LABEL_COLUMN,\n",
        "                                                    num_epochs=num_epochs,)\n",
        "                                                    #ignore_errors=True,\n",
        "    \n",
        "      \n",
        "    \n",
        "    dataset = dataset.prefetch(buffer_size = batch_size)\n",
        "    \n",
        "    dataset = dataset.map(feature_engg)\n",
        "\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        num_epochs = vnum_epochs # indefinitely\n",
        "        dataset = dataset.shuffle(buffer_size = batch_size)\n",
        "    else:\n",
        "        num_epochs = 1 # end-of-input after this\n",
        "\n",
        "    dataset = dataset.repeat(num_epochs)       \n",
        "    \n",
        "    #Begins - Uncomment for testing only -----------------------------------------------------<\n",
        "    if v_test == True:\n",
        "      print(next(dataset.__iter__()))\n",
        "      \n",
        "    #End - Uncomment for testing only -----------------------------------------------------<\n",
        "    return dataset\n",
        "  return _input_fn\n",
        "                                                            \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l61j46Ja3No",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcf16cee-a99a-44c2-d6c2-4883d34c3c35"
      },
      "source": [
        "eval_file = \"/content/drive/MyDrive/Expresso Churn/tfEval.csv\"\n",
        "fn_d = create_input_fn(filename = eval_file,\n",
        "                    mode = tf.estimator.ModeKeys.EVAL,\n",
        "                    # vnum_epochs = 1,\n",
        "                    batch_size = 10)\n",
        "\n",
        "fn_d(v_test=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(OrderedDict([('user_id', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
            "array([b'cd594dd11db6cdc666e681223d9c1c4e38f3d7e3',\n",
            "       b'cccdd540b8f829011e51949f8a3e2af01b7f46b4',\n",
            "       b'cd2fc8c609e7ae1f7c57332ca0936164f52aa3f4',\n",
            "       b'cd8dfaa386bbbfa3907ef5c161f11c370f069d8f',\n",
            "       b'cd4e7a19bab42b47c4842d2f2ca33923ff6f3943',\n",
            "       b'cd2c39ad3748fc40f8dd30b44df8f86a7e134498',\n",
            "       b'ccff156275b4405767ddf80d9cbf2333b87e9535',\n",
            "       b'cd1fbb1bc3569c4fd0d5c3930a2d9f4b38c627f1',\n",
            "       b'cd7affc0c23d1ee00365faa5f15200b2852764d2',\n",
            "       b'cce0ac547dca9676325dd7d4e1ce2f9935d2eb3a'], dtype=object)>), ('REGION', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
            "array([b'SAINT-LOUIS', b'DAKAR', b'not_given', b'DIOURBEL', b'not_given',\n",
            "       b'SAINT-LOUIS', b'not_given', b'KAOLACK', b'LOUGA', b'THIES'],\n",
            "      dtype=object)>), ('TENURE', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
            "array([b'I 18-21 month', b'K > 24 month', b'K > 24 month',\n",
            "       b'H 15-18 month', b'I 18-21 month', b'K > 24 month',\n",
            "       b'K > 24 month', b'K > 24 month', b'K > 24 month', b'K > 24 month'],\n",
            "      dtype=object)>), ('MONTANT', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([  500.,     0.,     0.,  8000.,   700.,  6000.,     0., 17600.,\n",
            "       17100., 17000.], dtype=float32)>), ('FREQUENCE_RECH', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([ 1.,  0.,  0., 16.,  2., 12.,  0., 36., 47., 32.], dtype=float32)>), ('REVENUE', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([  500.,     0.,     0.,  8501.,   700.,  5799.,     0., 18051.,\n",
            "       17097., 16500.], dtype=float32)>), ('ARPU_SEGMENT', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([ 167.,    0.,    0., 2834.,  233., 1933.,    0., 6017., 5699.,\n",
            "       5500.], dtype=float32)>), ('FREQUENCE', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([ 1.,  0.,  0., 17.,  2., 13.,  0., 36., 50., 32.], dtype=float32)>), ('DATA_VOLUME', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([  0.,   0.,   0.,   0.,  44., 191.,   0., 123.,   0.,   3.],\n",
            "      dtype=float32)>), ('ON_NET', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([   0.,    0.,    0.,   70.,    0.,   64.,    0.,  795., 3106.,\n",
            "        447.], dtype=float32)>), ('ORANGE', <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
            "array([  8.,   0.,   0., 229.,  21., 138.,   0., 333., 276., 498.],\n",
            "      dtype=float32)>), ('TIGO', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([ 2.,  0.,  0.,  3.,  0.,  4.,  0., 77.,  2., 56.], dtype=float32)>), ('ZONE1', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), ('ZONE2', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), ('MRG', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
            "array([b'NO', b'NO', b'NO', b'NO', b'NO', b'NO', b'NO', b'NO', b'NO',\n",
            "       b'NO'], dtype=object)>), ('REGULARITY', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([12.,  2.,  1., 16.,  1., 51.,  1., 59., 61., 59.], dtype=float32)>), ('TOP_PACK', <tf.Tensor: shape=(10,), dtype=string, numpy=\n",
            "array([b'All-net 500F=2000F;5d', b'not_given', b'not_given',\n",
            "       b'All-net 500F=2000F;5d', b'Data: 100 F=40MB,24H',\n",
            "       b'All-net 500F=2000F;5d', b'not_given',\n",
            "       b'MIXT:500F= 2500F on net _2500F off net;2d',\n",
            "       b'On net 200F=Unlimited _call24H',\n",
            "       b'MIXT:500F= 2500F on net _2500F off net;2d'], dtype=object)>), ('FREQ_TOP_PACK', <tf.Tensor: shape=(10,), dtype=float32, numpy=array([ 1.,  0.,  0., 17.,  1.,  6.,  0., 32., 20., 34.], dtype=float32)>)]), <tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 0, 1, 0, 0, 0, 1, 0, 0, 0], dtype=int32)>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RepeatDataset shapes: (OrderedDict([(user_id, (None,)), (REGION, (None,)), (TENURE, (None,)), (MONTANT, (None,)), (FREQUENCE_RECH, (None,)), (REVENUE, (None,)), (ARPU_SEGMENT, (None,)), (FREQUENCE, (None,)), (DATA_VOLUME, (None,)), (ON_NET, (None,)), (ORANGE, (None,)), (TIGO, (None,)), (ZONE1, (None,)), (ZONE2, (None,)), (MRG, (None,)), (REGULARITY, (None,)), (TOP_PACK, (None,)), (FREQ_TOP_PACK, (None,))]), (None,)), types: (OrderedDict([(user_id, tf.string), (REGION, tf.string), (TENURE, tf.string), (MONTANT, tf.float32), (FREQUENCE_RECH, tf.float32), (REVENUE, tf.float32), (ARPU_SEGMENT, tf.float32), (FREQUENCE, tf.float32), (DATA_VOLUME, tf.float32), (ON_NET, tf.float32), (ORANGE, tf.float32), (TIGO, tf.float32), (ZONE1, tf.float32), (ZONE2, tf.float32), (MRG, tf.string), (REGULARITY, tf.float32), (TOP_PACK, tf.string), (FREQ_TOP_PACK, tf.float32)]), tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Chh6r-_-QD4"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixCFYiBzCqtB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2700cf98-ab68-4596-b039-0e407d0dc164"
      },
      "source": [
        "def create_feature_columns():\n",
        "  k_region = tf.keras.Input(name=\"REGION\" , shape=(1,) , dtype= tf.string)\n",
        "  k_tenure = tf.keras.Input(name=\"TENURE\" , shape=(1,) , dtype= tf.string)\n",
        "  k_montant = tf.keras.Input(name=\"MONTANT\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_freq_rech = tf.keras.Input(name=\"FREQUENCE_RECH\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_revenue = tf.keras.Input(name=\"REVENUE\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_arpu_seg = tf.keras.Input(name=\"ARPU_SEGMENT\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_freq = tf.keras.Input(name=\"FREQUENCE\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_data_vol = tf.keras.Input(name=\"DATA_VOLUME\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_on_net = tf.keras.Input(name=\"ON_NET\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_orange = tf.keras.Input(name=\"ORANGE\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_tigo = tf.keras.Input(name=\"TIGO\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_zone1 = tf.keras.Input(name=\"ZONE1\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_zone2 = tf.keras.Input(name=\"ZONE2\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_mrg = tf.keras.Input(name=\"MRG\" , shape=(1,) , dtype= tf.string)\n",
        "  k_regularity = tf.keras.Input(name=\"REGULARITY\" , shape=(1,) , dtype= tf.float64)\n",
        "  k_top_pack = tf.keras.Input(name=\"TOP_PACK\" , shape=(1,) , dtype= tf.string)\n",
        "  k_freq_top_pack = tf.keras.Input(name=\"FREQ_TOP_PACK\" , shape=(1,) , dtype= tf.float64)\n",
        "\n",
        "  keras_input_dict = {'REGION':k_region, 'TENURE':k_tenure, 'MONTANT':k_montant, \n",
        "                      'FREQUENCE_RECH':k_freq_rech, 'REVENUE':k_revenue ,\n",
        "                      'ARPU_SEGMENT':k_arpu_seg, 'FREQUENCE':k_freq, \n",
        "                      'DATA_VOLUME':k_data_vol, 'ON_NET':k_on_net, 'ORANGE':k_orange, \n",
        "                      'TIGO':k_tigo, 'ZONE1':k_zone1, 'ZONE2':k_zone2, 'MRG':k_mrg, \n",
        "                      'REGULARITY':k_regularity, 'TOP_PACK':k_top_pack, \n",
        "                      'FREQ_TOP_PACK':k_freq_top_pack\n",
        "                      }\n",
        "\n",
        "  return ({'K':keras_input_dict})\n",
        "\n",
        "create_feature_columns()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'K': {'ARPU_SEGMENT': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'ARPU_SEGMENT')>,\n",
              "  'DATA_VOLUME': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'DATA_VOLUME')>,\n",
              "  'FREQUENCE': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'FREQUENCE')>,\n",
              "  'FREQUENCE_RECH': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'FREQUENCE_RECH')>,\n",
              "  'FREQ_TOP_PACK': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'FREQ_TOP_PACK')>,\n",
              "  'MONTANT': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'MONTANT')>,\n",
              "  'MRG': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'MRG')>,\n",
              "  'ON_NET': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'ON_NET')>,\n",
              "  'ORANGE': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'ORANGE')>,\n",
              "  'REGION': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'REGION')>,\n",
              "  'REGULARITY': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'REGULARITY')>,\n",
              "  'REVENUE': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'REVENUE')>,\n",
              "  'TENURE': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'TENURE')>,\n",
              "  'TIGO': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'TIGO')>,\n",
              "  'TOP_PACK': <KerasTensor: shape=(None, 1) dtype=string (created by layer 'TOP_PACK')>,\n",
              "  'ZONE1': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'ZONE1')>,\n",
              "  'ZONE2': <KerasTensor: shape=(None, 1) dtype=float64 (created by layer 'ZONE2')>}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtGrEjj0Cq1t"
      },
      "source": [
        "\n",
        "def create_model(feature_columns):\n",
        "  METRICS = [keras.metrics.MeanAbsoluteError(name='mae')]\n",
        "  input_features = []\n",
        "  counter = 0\n",
        "  for inp in feature_columns['K'].keys():\n",
        "    input_features.append(feature_columns['K'][inp])\n",
        "\n",
        "\n",
        "  # Categorical features preprocessing\n",
        "  cat_tenure = tf.keras.layers.StringLookup(vocabulary=unique_tenures, mask_token=None)(feature_columns['K']['TENURE'])\n",
        "  cat_tenure = tf.keras.layers.CategoryEncoding(num_tokens=len(unique_tenures)+3, output_mode='one_hot')(cat_tenure)\n",
        "  \n",
        "  cat_region = tf.keras.layers.StringLookup(vocabulary=unique_regions, mask_token=None)(feature_columns['K']['REGION'])\n",
        "  cat_region = tf.keras.layers.CategoryEncoding(num_tokens=len(unique_regions)+3, output_mode='one_hot')(cat_region)\n",
        "  #cat_top_pack = tf.keras.layers.experimental.preprocessing.CategoricalEncoding(max_tokens=200)(feature_columns['K']['TOP_PACK'])\n",
        "  \n",
        "  # Numerical values\n",
        "  all_numeric_features = tf.keras.layers.concatenate([\n",
        "                        feature_columns['K']['MONTANT'], feature_columns['K']['FREQUENCE_RECH'],\n",
        "                        feature_columns['K']['REVENUE'], feature_columns['K']['ARPU_SEGMENT'],\n",
        "                        feature_columns['K']['FREQUENCE'], feature_columns['K']['DATA_VOLUME'],\n",
        "                        feature_columns['K']['ON_NET'], feature_columns['K']['ORANGE'],\n",
        "                        feature_columns['K']['ZONE1'], feature_columns['K']['ZONE2'],\n",
        "                        feature_columns['K']['REGULARITY'], feature_columns['K']['FREQ_TOP_PACK'],\n",
        "                        ])\n",
        "  \n",
        "  all_categorical_columns = tf.keras.layers.concatenate([cat_tenure, cat_region])\n",
        "\n",
        "  x_numeric = tf.keras.layers.Dense(32, activation='sigmoid', input_shape=(100,), kernel_initializer=\"he_uniform\")(all_numeric_features)\n",
        "  x_numeric = tf.keras.layers.BatchNormalization()(x_numeric)\n",
        "\n",
        "  x_categorical = tf.keras.layers.Dense(32, activation='sigmoid', kernel_initializer=\"he_uniform\")(all_categorical_columns)\n",
        "  \n",
        "  x = tf.keras.layers.concatenate([x_numeric, x_categorical])\n",
        "  \n",
        "  # Creating the model\n",
        "  '''\n",
        "  x = tf.keras.layers.Reshape((64,1))(x)\n",
        " \n",
        "  x = tf.keras.layers.LSTM(20, return_sequences=True, dropout=0.2)(x)\n",
        "  x = tf.keras.layers.LSTM(20, return_sequences=True, dropout=0.2)(x)\n",
        "  x = tf.keras.layers.LSTM(20, dropout=0.2)(x)\n",
        "  \n",
        "  x = tf.keras.layers.Flatten()(x)\n",
        "  '''\n",
        "\n",
        "  x = tf.keras.layers.Dense(32, activation='sigmoid', kernel_initializer=\"he_uniform\",\n",
        "                                  activity_regularizer=tf.keras.regularizers.l2(0.00001))(x)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  \n",
        "  out = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = tf.keras.Model(input_features, out)\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(lr = 0.002)\n",
        "\n",
        "  #Compile the model\n",
        "  model.compile(loss='binary_crossentropy',optimizer=opt, metrics = METRICS )\n",
        "\n",
        "  print(model.summary())\n",
        "  print(model.output_shape)\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGF3InJ1wYL6"
      },
      "source": [
        "def train_and_evaluate(model, training_dataset , validation_dataset, epochs = 10):\n",
        "  reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                                patience=5, min_lr=0.00001, verbose = 1)\n",
        "  \n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "  #Train and Evaluate\n",
        "  out = model.fit(training_dataset, \n",
        "                  validation_data = validation_dataset,\n",
        "                  epochs=epochs,\n",
        "                  # validation_steps = 3,   ###Keep this none for running evaluation on full EVAL data every epoch\n",
        "                  steps_per_epoch = 100,   ###Has to be passed - Cant help it :) [ Number of batches per epoch ]\n",
        "                  callbacks=[reduce_lr, #modelsave_callback, #tensorboard_callback, \n",
        "                             keras.callbacks.EarlyStopping(patience=20, restore_best_weights=True, verbose=True)]\n",
        "                  )\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkZav4H-b2SO",
        "outputId": "d6850f39-db06-4983-ed20-0cd563f440d1"
      },
      "source": [
        "#Create dataset input functions\n",
        "train_dataset = create_input_fn(filename = \"/content/drive/MyDrive/Expresso Churn/tfTrain.csv\",\n",
        "                    mode = tf.estimator.ModeKeys.TRAIN,\n",
        "                    # vnum_epochs = epochs,\n",
        "                    batch_size = 128)()\n",
        "\n",
        "validation_dataset = create_input_fn(filename = \"/content/drive/MyDrive/Expresso Churn/tfEval.csv\",\n",
        "                    mode = tf.estimator.ModeKeys.EVAL,\n",
        "                    # vnum_epochs = 1,\n",
        "                    batch_size = 512)()\n",
        "\n",
        "m_ = create_model(feature_columns = create_feature_columns())\n",
        "#tf.keras.utils.plot_model(m_, show_shapes=True, rankdir=\"LR\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " TENURE (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " REGION (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " MONTANT (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " FREQUENCE_RECH (InputLayer)    [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " REVENUE (InputLayer)           [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ARPU_SEGMENT (InputLayer)      [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " FREQUENCE (InputLayer)         [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " DATA_VOLUME (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ON_NET (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ORANGE (InputLayer)            [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ZONE1 (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " ZONE2 (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " REGULARITY (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " FREQ_TOP_PACK (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " string_lookup (StringLookup)   (None, 1)            0           ['TENURE[0][0]']                 \n",
            "                                                                                                  \n",
            " string_lookup_1 (StringLookup)  (None, 1)           0           ['REGION[0][0]']                 \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 12)           0           ['MONTANT[0][0]',                \n",
            "                                                                  'FREQUENCE_RECH[0][0]',         \n",
            "                                                                  'REVENUE[0][0]',                \n",
            "                                                                  'ARPU_SEGMENT[0][0]',           \n",
            "                                                                  'FREQUENCE[0][0]',              \n",
            "                                                                  'DATA_VOLUME[0][0]',            \n",
            "                                                                  'ON_NET[0][0]',                 \n",
            "                                                                  'ORANGE[0][0]',                 \n",
            "                                                                  'ZONE1[0][0]',                  \n",
            "                                                                  'ZONE2[0][0]',                  \n",
            "                                                                  'REGULARITY[0][0]',             \n",
            "                                                                  'FREQ_TOP_PACK[0][0]']          \n",
            "                                                                                                  \n",
            " category_encoding (CategoryEnc  (None, 11)          0           ['string_lookup[0][0]']          \n",
            " oding)                                                                                           \n",
            "                                                                                                  \n",
            " category_encoding_1 (CategoryE  (None, 18)          0           ['string_lookup_1[0][0]']        \n",
            " ncoding)                                                                                         \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           416         ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 29)           0           ['category_encoding[0][0]',      \n",
            "                                                                  'category_encoding_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32)          128         ['dense[0][0]']                  \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           960         ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 64)           0           ['batch_normalization[0][0]',    \n",
            "                                                                  'dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           2080        ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32)          128         ['dense_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " TIGO (InputLayer)              [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " MRG (InputLayer)               [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " TOP_PACK (InputLayer)          [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1)            33          ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3,745\n",
            "Trainable params: 3,617\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "(None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJzf6aAJb2W9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa751d1-b830-4474-f43c-ba9a2fa65fa8"
      },
      "source": [
        "train_and_evaluate(m_, train_dataset, validation_dataset, 30)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "100/100 [==============================] - 18s 155ms/step - loss: 0.4195 - mae: 0.2838 - val_loss: 0.4214 - val_mae: 0.2998 - lr: 0.0020\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 0.2880 - mae: 0.1924 - val_loss: 0.3671 - val_mae: 0.2249 - lr: 0.0020\n",
            "Epoch 3/30\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.2805 - mae: 0.1819 - val_loss: 0.3102 - val_mae: 0.2110 - lr: 0.0020\n",
            "Epoch 4/30\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.2753 - mae: 0.1737 - val_loss: 0.2815 - val_mae: 0.1943 - lr: 0.0020\n",
            "Epoch 5/30\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.2753 - mae: 0.1736 - val_loss: 0.3035 - val_mae: 0.1902 - lr: 0.0020\n",
            "Epoch 6/30\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.2755 - mae: 0.1744 - val_loss: 0.2791 - val_mae: 0.1937 - lr: 0.0020\n",
            "Epoch 7/30\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.2772 - mae: 0.1721 - val_loss: 0.2744 - val_mae: 0.1754 - lr: 0.0020\n",
            "Epoch 8/30\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.2843 - mae: 0.1777 - val_loss: 0.2740 - val_mae: 0.1817 - lr: 0.0020\n",
            "Epoch 9/30\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.2597 - mae: 0.1649 - val_loss: 0.2692 - val_mae: 0.1769 - lr: 0.0020\n",
            "Epoch 10/30\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.2717 - mae: 0.1730 - val_loss: 0.2759 - val_mae: 0.1782 - lr: 0.0020\n",
            "Epoch 11/30\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2788 - mae: 0.1742 - val_loss: 0.2727 - val_mae: 0.1696 - lr: 0.0020\n",
            "Epoch 12/30\n",
            "100/100 [==============================] - 13s 134ms/step - loss: 0.2776 - mae: 0.1770 - val_loss: 0.2716 - val_mae: 0.1732 - lr: 0.0020\n",
            "Epoch 13/30\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.2747 - mae: 0.1752 - val_loss: 0.2713 - val_mae: 0.1779 - lr: 0.0020\n",
            "Epoch 14/30\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 0.2759 - mae: 0.1739\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
            "100/100 [==============================] - 13s 135ms/step - loss: 0.2761 - mae: 0.1742 - val_loss: 0.2707 - val_mae: 0.1720 - lr: 0.0020\n",
            "Epoch 15/30\n",
            "100/100 [==============================] - 13s 132ms/step - loss: 0.2706 - mae: 0.1716 - val_loss: 0.2690 - val_mae: 0.1747 - lr: 4.0000e-04\n",
            "Epoch 16/30\n",
            "100/100 [==============================] - 14s 140ms/step - loss: 0.2738 - mae: 0.1739 - val_loss: 0.2681 - val_mae: 0.1727 - lr: 4.0000e-04\n",
            "Epoch 17/30\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.2662 - mae: 0.1714 - val_loss: 0.2679 - val_mae: 0.1708 - lr: 4.0000e-04\n",
            "Epoch 18/30\n",
            "100/100 [==============================] - 21s 216ms/step - loss: 0.2643 - mae: 0.1682 - val_loss: 0.2678 - val_mae: 0.1691 - lr: 4.0000e-04\n",
            "Epoch 19/30\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2708 - mae: 0.1720 - val_loss: 0.2678 - val_mae: 0.1717 - lr: 4.0000e-04\n",
            "Epoch 20/30\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2697 - mae: 0.1725 - val_loss: 0.2676 - val_mae: 0.1723 - lr: 4.0000e-04\n",
            "Epoch 21/30\n",
            "100/100 [==============================] - 14s 138ms/step - loss: 0.2722 - mae: 0.1716 - val_loss: 0.2674 - val_mae: 0.1721 - lr: 4.0000e-04\n",
            "Epoch 22/30\n",
            "100/100 [==============================] - 13s 130ms/step - loss: 0.2807 - mae: 0.1756 - val_loss: 0.2673 - val_mae: 0.1731 - lr: 4.0000e-04\n",
            "Epoch 23/30\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2677 - mae: 0.1692 - val_loss: 0.2682 - val_mae: 0.1735 - lr: 4.0000e-04\n",
            "Epoch 24/30\n",
            "100/100 [==============================] - 13s 131ms/step - loss: 0.2651 - mae: 0.1692 - val_loss: 0.2675 - val_mae: 0.1700 - lr: 4.0000e-04\n",
            "Epoch 25/30\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.2794 - mae: 0.1753 - val_loss: 0.2678 - val_mae: 0.1730 - lr: 4.0000e-04\n",
            "Epoch 26/30\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 0.2687 - mae: 0.1706\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.2688 - mae: 0.1707 - val_loss: 0.2683 - val_mae: 0.1715 - lr: 4.0000e-04\n",
            "Epoch 27/30\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2693 - mae: 0.1730 - val_loss: 0.2673 - val_mae: 0.1714 - lr: 8.0000e-05\n",
            "Epoch 28/30\n",
            "100/100 [==============================] - 13s 129ms/step - loss: 0.2703 - mae: 0.1710 - val_loss: 0.2671 - val_mae: 0.1703 - lr: 8.0000e-05\n",
            "Epoch 29/30\n",
            "100/100 [==============================] - 13s 128ms/step - loss: 0.2631 - mae: 0.1680 - val_loss: 0.2670 - val_mae: 0.1701 - lr: 8.0000e-05\n",
            "Epoch 30/30\n",
            "100/100 [==============================] - 21s 217ms/step - loss: 0.2695 - mae: 0.1717 - val_loss: 0.2669 - val_mae: 0.1698 - lr: 8.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWTDB1YYwYUS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0deb69a-cebc-4f4e-b82c-ff4400b3c1cb"
      },
      "source": [
        "#Trying out an example\n",
        "data = tf.data.Dataset.from_tensor_slices({\n",
        "    'REGION': [['THIES']],\n",
        "    'TENURE': [['K > 24 month']],\n",
        "    'MONTANT':[[1000]],\n",
        "    'FREQUENCE_RECH':[[2]],\n",
        "    'REVENUE':[[990]],\n",
        "    'ARPU_SEGMENT':[[330]],\n",
        "    'FREQUENCE':[[3]],\n",
        "    'DATA_VOLUME':[[2268]],\n",
        "    'ON_NET':[[7]],\n",
        "    'ORANGE':[[10]],\n",
        "    'TIGO':[[4]],\n",
        "    'ZONE1':[[0]],\n",
        "    'ZONE2':[[0]],\n",
        "    'MRG':[['NO']],\n",
        "    'REGULARITY':[[8]],\n",
        "    'TOP_PACK':[['Data:490F=1GB,7d']],\n",
        "    'FREQ_TOP_PACK':[[2]]\n",
        "})\n",
        "m_.predict(data)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0103]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvhxDyqZanBy"
      },
      "source": [
        "@tf.function\n",
        "def serving(region,tenure,montant,frequence_rech, revenue, \n",
        "            arpu_segment, frequence, data_volume, on_net, orange, \n",
        "            tigo, zone1, zone2, mrg, regularity, top_pack, freq_top_pack):\n",
        "  payload = {\n",
        "      'REGION': region,\n",
        "      'TENURE': tenure,\n",
        "      'MONTANT':montant,\n",
        "      'FREQUENCE_RECH':frequence_rech,\n",
        "      'REVENUE':revenue,\n",
        "      'ARPU_SEGMENT':arpu_segment,\n",
        "      'FREQUENCE':frequence,\n",
        "      'DATA_VOLUME':data_volume,\n",
        "      'ON_NET':on_net,\n",
        "      'ORANGE':orange,\n",
        "      'TIGO':tigo,\n",
        "      'ZONE1':zone1,\n",
        "      'ZONE2':zone2,\n",
        "      'MRG':mrg,\n",
        "      'REGULARITY':regularity,\n",
        "      'TOP_PACK':top_pack,\n",
        "      'FREQ_TOP_PACK':freq_top_pack,      \n",
        "      }\n",
        "    \n",
        "  predictions = m_(payload)\n",
        "  return predictions"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIDyg2_ZwYYj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f10aa6b-58b4-4f47-e018-6c8c13ec5406"
      },
      "source": [
        "serving = serving.get_concrete_function(region=tf.TensorSpec([None,], dtype= tf.string, name='region'),\n",
        "                                        tenure=tf.TensorSpec([None,], dtype= tf.string, name='tenure'),\n",
        "                                        montant=tf.TensorSpec([None,], dtype= tf.float64, name='montant'),\n",
        "                                        frequence_rech=tf.TensorSpec([None,], dtype= tf.float64, name='frequence_rech'), \n",
        "                                        revenue=tf.TensorSpec([None,], dtype= tf.float64, name='revenue'), \n",
        "                                        arpu_segment=tf.TensorSpec([None,], dtype= tf.float64, name='arpu_segment'), \n",
        "                                        frequence=tf.TensorSpec([None,], dtype= tf.float64, name='frequence'), \n",
        "                                        data_volume=tf.TensorSpec([None,], dtype= tf.float64, name='data_volume'), \n",
        "                                        on_net=tf.TensorSpec([None,], dtype= tf.float64, name='on_net'), \n",
        "                                        orange=tf.TensorSpec([None,], dtype= tf.float64, name='orange'), \n",
        "                                        tigo=tf.TensorSpec([None,], dtype= tf.float64, name='tigo'), \n",
        "                                        zone1=tf.TensorSpec([None,], dtype= tf.float64, name='zone1'), \n",
        "                                        zone2=tf.TensorSpec([None,], dtype= tf.float64, name='zone2'), \n",
        "                                        mrg=tf.TensorSpec([None,], dtype= tf.string, name='mrg'), \n",
        "                                        regularity=tf.TensorSpec([None,], dtype= tf.float64, name='regularity'), \n",
        "                                        top_pack=tf.TensorSpec([None,], dtype= tf.string, name='top_pack'), \n",
        "                                        freq_top_pack=tf.TensorSpec([None,], dtype= tf.float64, name='freq_top_pack')\n",
        "                                        )\n",
        "\n",
        "version = \"1\"  #{'serving_default': call_output}\n",
        "tf.saved_model.save(\n",
        "    m_,\n",
        "    \"/content/drive/MyDrive/Expresso Churn/expresso_churn_model/\" + version,\n",
        "    signatures=serving\n",
        ") \n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59MjqGs7Yauk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ad5cb18-c280-46ab-f7e7-52b79095ef99"
      },
      "source": [
        "!tar -cvf /content/model.tar '/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/'"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/variables/\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/variables/variables.index\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/variables/variables.data-00000-of-00001\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/assets/\n",
            "/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1/saved_model.pb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWu1lvzLgvwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "059afe4b-c00f-4111-bd8b-760c1ad6b380"
      },
      "source": [
        "##Check signature\n",
        "!saved_model_cli show --dir \"/content/drive/MyDrive/Expresso Churn/expresso_churn_model/1\" --all"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['__saved_model_init_op']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['__saved_model_init_op'] tensor_info:\n",
            "        dtype: DT_INVALID\n",
            "        shape: unknown_rank\n",
            "        name: NoOp\n",
            "  Method name is: \n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['arpu_segment'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_arpu_segment:0\n",
            "    inputs['data_volume'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_data_volume:0\n",
            "    inputs['freq_top_pack'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_freq_top_pack:0\n",
            "    inputs['frequence'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_frequence:0\n",
            "    inputs['frequence_rech'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_frequence_rech:0\n",
            "    inputs['montant'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_montant:0\n",
            "    inputs['mrg'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1)\n",
            "        name: serving_default_mrg:0\n",
            "    inputs['on_net'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_on_net:0\n",
            "    inputs['orange'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_orange:0\n",
            "    inputs['region'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1)\n",
            "        name: serving_default_region:0\n",
            "    inputs['regularity'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_regularity:0\n",
            "    inputs['revenue'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_revenue:0\n",
            "    inputs['tenure'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1)\n",
            "        name: serving_default_tenure:0\n",
            "    inputs['tigo'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_tigo:0\n",
            "    inputs['top_pack'] tensor_info:\n",
            "        dtype: DT_STRING\n",
            "        shape: (-1)\n",
            "        name: serving_default_top_pack:0\n",
            "    inputs['zone1'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_zone1:0\n",
            "    inputs['zone2'] tensor_info:\n",
            "        dtype: DT_DOUBLE\n",
            "        shape: (-1)\n",
            "        name: serving_default_zone2:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['output_0'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 1)\n",
            "        name: StatefulPartitionedCall_2:0\n",
            "  Method name is: tensorflow/serving/predict\n",
            "\n",
            "Defined Functions:\n",
            "  Function Name: '__call__'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='REGION'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TENURE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='MONTANT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE_RECH'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REVENUE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ARPU_SEGMENT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='DATA_VOLUME'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ON_NET'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ORANGE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='TIGO'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE2'), TensorSpec(shape=(None, 1), dtype=tf.string, name='MRG'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REGULARITY'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TOP_PACK'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQ_TOP_PACK'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/0'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/2'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/3'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/4'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/5'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/6'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/7'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/8'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/9'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/10'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/11'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/12'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/13'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/14'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/15'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/16'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='REGION'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TENURE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='MONTANT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE_RECH'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REVENUE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ARPU_SEGMENT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='DATA_VOLUME'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ON_NET'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ORANGE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='TIGO'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE2'), TensorSpec(shape=(None, 1), dtype=tf.string, name='MRG'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REGULARITY'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TOP_PACK'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQ_TOP_PACK'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/0'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/2'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/3'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/4'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/5'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/6'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/7'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/8'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/9'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/10'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/11'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/12'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/13'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/14'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/15'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/16'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "\n",
            "  Function Name: '_default_save_signature'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='REGION'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TENURE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='MONTANT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE_RECH'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REVENUE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ARPU_SEGMENT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='DATA_VOLUME'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ON_NET'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ORANGE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='TIGO'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE2'), TensorSpec(shape=(None, 1), dtype=tf.string, name='MRG'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REGULARITY'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TOP_PACK'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQ_TOP_PACK'), \b\b]\n",
            "\n",
            "  Function Name: 'call_and_return_all_conditional_losses'\n",
            "    Option #1\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/0'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/2'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/3'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/4'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/5'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/6'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/7'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/8'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/9'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/10'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/11'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/12'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/13'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/14'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/15'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/16'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #2\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='REGION'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TENURE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='MONTANT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE_RECH'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REVENUE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ARPU_SEGMENT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='DATA_VOLUME'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ON_NET'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ORANGE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='TIGO'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE2'), TensorSpec(shape=(None, 1), dtype=tf.string, name='MRG'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REGULARITY'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TOP_PACK'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQ_TOP_PACK'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: False\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #3\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='REGION'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TENURE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='MONTANT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE_RECH'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REVENUE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ARPU_SEGMENT'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQUENCE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='DATA_VOLUME'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ON_NET'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ORANGE'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='TIGO'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='ZONE2'), TensorSpec(shape=(None, 1), dtype=tf.string, name='MRG'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='REGULARITY'), TensorSpec(shape=(None, 1), dtype=tf.string, name='TOP_PACK'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='FREQ_TOP_PACK'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n",
            "    Option #4\n",
            "      Callable with:\n",
            "        Argument #1\n",
            "          DType: list\n",
            "          Value: [TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/0'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/1'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/2'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/3'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/4'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/5'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/6'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/7'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/8'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/9'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/10'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/11'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/12'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/13'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/14'), TensorSpec(shape=(None, 1), dtype=tf.string, name='inputs/15'), TensorSpec(shape=(None, 1), dtype=tf.float64, name='inputs/16'), \b\b]\n",
            "        Argument #2\n",
            "          DType: bool\n",
            "          Value: True\n",
            "        Argument #3\n",
            "          DType: NoneType\n",
            "          Value: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIIYTEzkhB8j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740d0fc4-094b-4fad-d3b1-c5f991344acf"
      },
      "source": [
        "#LOCAL: Predict using Keras prediction function\n",
        "saved_mod = tf.saved_model.load(\"/content/drive/MyDrive/Expresso Churn/expresso_churn_model/\" + version)\n",
        "\n",
        "#Get prediction function from serving\n",
        "f = saved_mod.signatures['serving_default']\n",
        "\n",
        "#Run prediction function from serving\n",
        "# Casting all numeric to double since it was what we used to create the model\n",
        "# results ini an error otherwise\n",
        "f(region= tf.convert_to_tensor(['THIES']),\n",
        "    tenure= tf.convert_to_tensor(['K > 24 month']),\n",
        "    montant= tf.cast(tf.convert_to_tensor([1000]), tf.float64),\n",
        "    frequence_rech= tf.cast(tf.convert_to_tensor([2]), tf.float64),\n",
        "    revenue = tf.cast(tf.convert_to_tensor([990]), tf.float64),\n",
        "    arpu_segment = tf.cast(tf.convert_to_tensor([330]), tf.float64),\n",
        "    frequence = tf.cast(tf.convert_to_tensor([3]), tf.float64),\n",
        "    data_volume = tf.cast(tf.convert_to_tensor([2268]), tf.float64),\n",
        "    on_net = tf.cast(tf.convert_to_tensor([7]), tf.float64),\n",
        "    orange = tf.cast(tf.convert_to_tensor([10]), tf.float64),\n",
        "    tigo = tf.cast(tf.convert_to_tensor([4]), tf.float64),\n",
        "    zone1 = tf.cast(tf.convert_to_tensor([0]), tf.float64),\n",
        "    zone2 = tf.cast(tf.convert_to_tensor([0]), tf.float64),\n",
        "    mrg = tf.convert_to_tensor(['NO']),\n",
        "    regularity = tf.cast(tf.convert_to_tensor([8]), tf.float64),\n",
        "    top_pack = tf.convert_to_tensor(['Data:490F=1GB,7d']),\n",
        "    freq_top_pack = tf.cast(tf.convert_to_tensor([2]), tf.float64)\n",
        "    )"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'output_0': <tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.0103]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMDQXZyozpOt"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PkFXoL2zpTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd769e3e-f32a-4ccf-b352-d946d6f7cc5e"
      },
      "source": [
        "###Install TF Model server\n",
        "\n",
        "# This is the same as you would do from your command line, but without the [arch=amd64], and no sudo\n",
        "# You would instead do:\n",
        "# echo \"deb [arch=amd64] http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | sudo tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "# curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | sudo apt-key add -\n",
        "\n",
        "!apt-get remove tensorflow-model-server\n",
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n",
        "\n",
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages will be REMOVED:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 0 newly installed, 1 to remove and 100 not upgraded.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "(Reading database ... 155223 files and directories currently installed.)\n",
            "Removing tensorflow-model-server (2.7.0) ...\n",
            "deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2943  100  2943    0     0  89181      0 --:--:-- --:--:-- --:--:-- 91968\n",
            "OK\n",
            "Hit:1 http://storage.googleapis.com/tensorflow-serving-apt stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "100 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tensorflow-model-server\n",
            "0 upgraded, 1 newly installed, 0 to remove and 100 not upgraded.\n",
            "Need to get 335 MB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 http://storage.googleapis.com/tensorflow-serving-apt stable/tensorflow-model-server amd64 tensorflow-model-server all 2.7.0 [335 MB]\n",
            "Fetched 335 MB in 5s (74.5 MB/s)\n",
            "Selecting previously unselected package tensorflow-model-server.\n",
            "(Reading database ... 155222 files and directories currently installed.)\n",
            "Preparing to unpack .../tensorflow-model-server_2.7.0_all.deb ...\n",
            "Unpacking tensorflow-model-server (2.7.0) ...\n",
            "Setting up tensorflow-model-server (2.7.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaC1tWWpzpXu"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNAjN-c9zpcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4219ced-7831-4ad2-cef8-16448673cfe1"
      },
      "source": [
        "###Start Tensorflow server\n",
        "# %%bash --bg \n",
        "# export TF_CPP_MIN_VLOG_LEVEL=0\n",
        "\n",
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8505 \\\n",
        "  --model_name=model \\\n",
        "  --model_base_path=\"/content/drive/MyDrive/Expresso Churn/expresso_churn_model\" >server.log 2>&1"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6eCJ2Lpzpg1"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBXqyN4lhOz7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "371e2014-61ca-4cd8-d8c0-371f29f33940"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "#Create payload\n",
        "data_py = {\"instances\":[{'region': 'THIES',\n",
        "                        'tenure': 'K > 24 month',\n",
        "                        'montant':10,\n",
        "                        'frequence_rech':20,\n",
        "                        'revenue':9,\n",
        "                        'arpu_segment':300,\n",
        "                        'frequence':30,\n",
        "                        'data_volume':22,\n",
        "                        'on_net':20,\n",
        "                        'orange':10,\n",
        "                        'tigo':40,\n",
        "                        'zone1':0,\n",
        "                        'zone2':0,\n",
        "                        'mrg':'NO',\n",
        "                        'regularity':8,\n",
        "                        'top_pack':'Data:490F=1GB,7d',\n",
        "                        'freq_top_pack':20\n",
        "                         }]}\n",
        "\n",
        "data = json.dumps(data_py)\n",
        "#print(\"payload: \", data)\n",
        "\n",
        "#Run request on TMS\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8505/v1/models/model:predict', data=data, headers=headers)\n",
        "json_response.text"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\n    \"predictions\": [[0.339752972]\\n    ]\\n}'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3T1RdRiEhO3d"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    }
  ]
}